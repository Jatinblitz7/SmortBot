{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b595ea2-d951-4071-aec3-e98cd3e10c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jatin\\BotProj\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gradio as gr\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "FAISS_FILE = \"faiss_store.pkl\"\n",
    "\n",
    "# Load text generation pipeline using a lightweight T5 model\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "hf_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"MBZUAI/LaMini-Flan-T5-783M\",\n",
    "    device=device,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=False,\n",
    "    temperature=0\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# Custom prompt template for focused and honest answers\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant. Answer the question strictly using the context. \n",
    "If the answer is not about the exact car model mentioned in the question, say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Function to load and process news articles from URLs\n",
    "def process_urls(url1, url2, url3, progress=gr.Progress()):\n",
    "    urls = [url1, url2, url3]\n",
    "    loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "    progress(0.1, desc=\"Loading articles\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Basic cleaning to remove unwanted boilerplate from news content\n",
    "    def clean_text(text):\n",
    "        import re\n",
    "        return re.sub(r\"(Remove Ad|Story continues below.*?|Reuters|Advertisement)\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    for doc in docs:\n",
    "        doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "    # Split documents into manageable chunks for embedding\n",
    "    progress(0.4, desc=\"Splitting content into chunks\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=80)\n",
    "    splits = splitter.split_documents(docs)\n",
    "\n",
    "    # Create vector embeddings using a pre-trained MiniLM model\n",
    "    progress(0.6, desc=\"Generating embeddings\")\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(splits, embedding)\n",
    "\n",
    "    # Save the vectorstore to disk\n",
    "    progress(0.9, desc=\"Saving processed data\")\n",
    "    with open(FAISS_FILE, \"wb\") as f:\n",
    "        pickle.dump(vectorstore, f)\n",
    "\n",
    "    progress(1.0, desc=\"Completed processing\")\n",
    "    return \"Articles processed and saved successfully.\"\n",
    "\n",
    "# Function to query the processed articles using the LLM\n",
    "def answer_query(question):\n",
    "    if not os.path.exists(FAISS_FILE):\n",
    "        return \"Please process the articles first.\", \"\"\n",
    "\n",
    "    with open(FAISS_FILE, \"rb\") as f:\n",
    "        vectorstore = pickle.load(f)\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", k=3)\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": custom_prompt}\n",
    "    )\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    answer = result[\"result\"]\n",
    "    sources = \"\\n\".join(set(doc.metadata[\"source\"] for doc in result[\"source_documents\"]))\n",
    "    return answer, sources\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks(\n",
    "    css=\"\"\"\n",
    "    #title-container {\n",
    "        text-align: center;\n",
    "        padding: 2rem 1rem;\n",
    "        background: linear-gradient(135deg, #eef6ff, #ffffff);\n",
    "        border-radius: 20px;\n",
    "        margin-bottom: 25px;\n",
    "        box-shadow: 0 6px 24px rgba(0, 0, 0, 0.06);\n",
    "    }\n",
    "\n",
    "    #title-container h1 {\n",
    "        font-size: 3rem;\n",
    "        font-weight: 800;\n",
    "        color: #1a365d;\n",
    "        margin-bottom: 0.4rem;\n",
    "    }\n",
    "\n",
    "    #title-container p {\n",
    "        font-size: 1.2rem;\n",
    "        color: #2d3748;\n",
    "        max-width: 820px;\n",
    "        margin: 0 auto;\n",
    "        line-height: 1.7;\n",
    "    }\n",
    "\n",
    "    .tab-panel {\n",
    "        background-color: #ffffff;\n",
    "        padding: 24px;\n",
    "        border-radius: 16px;\n",
    "        box-shadow: 0 2px 12px rgba(0, 0, 0, 0.05);\n",
    "        margin-top: 10px;\n",
    "    }\n",
    "\n",
    "    .gr-button {\n",
    "        background: linear-gradient(135deg, #3182ce, #63b3ed) !important;\n",
    "        color: white !important;\n",
    "        font-weight: bold;\n",
    "        border-radius: 8px !important;\n",
    "        padding: 10px 20px !important;\n",
    "    }\n",
    "\n",
    "    .gr-textbox label {\n",
    "        font-weight: 600;\n",
    "        color: #1a202c;\n",
    "    }\n",
    "\n",
    "    .gr-textbox textarea, .gr-textbox input {\n",
    "        border-radius: 6px !important;\n",
    "        border: 1px solid #cbd5e0 !important;\n",
    "    }\n",
    "    \"\"\",\n",
    "    theme=gr.themes.Default(primary_hue=\"blue\")\n",
    ") as demo:\n",
    "\n",
    "    gr.Markdown(\"\"\"\n",
    "        <div id=\"title-container\">\n",
    "            <h1>üß† SmortBot</h1>\n",
    "            <p>\n",
    "                Turn news into knowledge in seconds! Paste article links, ask your questions, and get smart answers with sources. <br>\n",
    "                Powered by LangChain, HuggingFace, and FAISS ‚Äî all wrapped in a user-friendly Gradio interface.\n",
    "            </p>\n",
    "        </div>\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Tab(\"üîó Step 1: Load Article URLs\"):\n",
    "        with gr.Row(elem_classes=\"tab-panel\"):\n",
    "            with gr.Column():\n",
    "                url1 = gr.Textbox(label=\"üîç News URL 1\", placeholder=\"Paste article link here...\", lines=1)\n",
    "                url2 = gr.Textbox(label=\"üîç News URL 2\", placeholder=\"Optional second link...\", lines=1)\n",
    "                url3 = gr.Textbox(label=\"üîç News URL 3\", placeholder=\"Optional third link...\", lines=1)\n",
    "                process_btn = gr.Button(\"üöÄ Process Articles\")\n",
    "                process_status = gr.Textbox(label=\"üìÑ Status\", interactive=False)\n",
    "\n",
    "        process_btn.click(process_urls, inputs=[url1, url2, url3], outputs=process_status)\n",
    "\n",
    "    with gr.Tab(\"‚ùì Step 2: Ask a Question\"):\n",
    "        with gr.Row(elem_classes=\"tab-panel\"):\n",
    "            question = gr.Textbox(label=\"ü§î Your Question\", placeholder=\"Ask something related to the articles\", lines=2)\n",
    "        with gr.Row(elem_classes=\"tab-panel\"):\n",
    "            answer = gr.Textbox(label=\"üí° SmortBot‚Äôs Answer\", lines=4, interactive=False)\n",
    "        with gr.Row(elem_classes=\"tab-panel\"):\n",
    "            sources = gr.Textbox(label=\"üîó Sources Used\", lines=3, interactive=False)\n",
    "        ask_btn = gr.Button(\"üí¨ Get Answer\")\n",
    "        ask_btn.click(answer_query, inputs=question, outputs=[answer, sources])\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
